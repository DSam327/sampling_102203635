{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "00c2b650-f8a1-4654-a427-074a00b2ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81cd761f-7afa-4242-a1cf-84f03dffd36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(r\"../Downloads/Creditcard_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b65ab889-5f49-4f3d-adca-c5bcbb80e386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    763\n",
       "1      9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53c50df7-a2d1-497e-b548-154abaea5ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_class = raw_data[raw_data['Class'] == 0]\n",
    "minority_classes = raw_data[raw_data['Class'] != 0]\n",
    "\n",
    "# Upsample the minority classes\n",
    "minority_upsampled = resample(minority_classes,\n",
    "                              replace=True, \n",
    "                              n_samples=len(majority_class))  \n",
    "\n",
    "# Combine majority and minority and thus shufle the result\n",
    "df_upsampled = pd.concat([majority_class, minority_upsampled])\n",
    "df_upsampled = df_upsampled.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc6967b4-c2e9-4aec-a337-755a4c718731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    763\n",
       "1    763\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upsampled['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "108fc00f-2e3c-4df9-bb79-6abdf5a5fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sample_size(population_size, proportion=0.5):\n",
    "    Z = 1.96\n",
    "    E = 0.05\n",
    "    p = proportion\n",
    "    n = (Z**2 * p * (1 - p)) / (E**2)\n",
    "    # Adjust for finite population\n",
    "    n = n / (1 + (n - 1) / population_size)\n",
    "    return int(np.ceil(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5314ab5d-50cd-4959-bbb2-7450fcceafd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling methods with calculated sample size\n",
    "def simple_random_sampling(X, y):\n",
    "    size= calculate_sample_size(len(x))\n",
    "    population_size=len(X)\n",
    "    X_sample, _, y_sample, _ = train_test_split(X, y, train_size=size/population_size, random_state=42)\n",
    "    return X_sample, y_sample\n",
    "\n",
    "def systematic_sampling(X, y):\n",
    "    size= calculate_sample_size(len(x))\n",
    "    population_size=len(X)\n",
    "    step = len(X) // size\n",
    "    indices = np.arange(len(X))\n",
    "    systematic_indices = indices[::step][:size]\n",
    "    return X.iloc[systematic_indices], y.iloc[systematic_indices]\n",
    "\n",
    "def stratified_sampling(X, y):\n",
    "    size= calculate_sample_size(len(x))\n",
    "    population_size=len(X)\n",
    "    X_sample, _, y_sample, _ = train_test_split(X, y, train_size=size/population_size, stratify=y, random_state=42)\n",
    "    return X_sample, y_sample\n",
    "\n",
    "def cluster_sampling(X, y,n_clusters=3):\n",
    "    clusters = np.array_split(X.index, n_clusters)\n",
    "    chosen_cluster = clusters[np.random.choice(len(clusters))]\n",
    "    return X.loc[chosen_cluster], y.loc[chosen_cluster]\n",
    "\n",
    "def bootstrap_sampling(X, y):\n",
    "    size= calculate_sample_size(len(x))\n",
    "    population_size=len(X)\n",
    "    X_resampled, y_resampled = resample(X, y, replace=True, n_samples=size, random_state=42)\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1a9094a9-24c3-4859-b73c-4e885b4b286d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samra\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\samra\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\samra\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\samra\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\samra\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Split into features and labels\n",
    "x = df_upsampled.drop(columns=[\"Class\"])  # Replace 'target' with your label column name\n",
    "y = df_upsampled[\"Class\"]\n",
    "\n",
    "samples=create_samples(x,y)\n",
    "\n",
    "# Models to Evaluate\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Apply each sampling method\n",
    "sampling_methods = {\n",
    "    \"Simple Random\": simple_random_sampling,\n",
    "    \"Systematic\": systematic_sampling,\n",
    "    \"Stratified\": stratified_sampling,\n",
    "    \"Cluster\": cluster_sampling,\n",
    "    \"Bootstrap\": bootstrap_sampling\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    for sampling_name, sampling_func in sampling_methods.items():\n",
    "        # Apply sampling\n",
    "        X_sample, y_sample = sampling_func(x, y)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.3)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\"Model\": model_name, \"Sampling\": sampling_name, \"Accuracy\": accuracy})\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d0655f74-3f9c-4b0c-bc49-b40caabddb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model          K-Nearest Neighbors  Logistic Regression  Random Forest  \\\n",
      "Sampling                                                                 \n",
      "Bootstrap                 0.935484             0.913978       1.000000   \n",
      "Cluster                   0.973856             0.888889       1.000000   \n",
      "Simple Random             0.903226             0.913978       0.989247   \n",
      "Stratified                0.946237             0.903226       0.978495   \n",
      "Systematic                0.956989             0.967742       1.000000   \n",
      "\n",
      "Model          Support Vector Machine   XGBoost  \n",
      "Sampling                                         \n",
      "Bootstrap                    0.698925  1.000000  \n",
      "Cluster                      0.692810  0.993464  \n",
      "Simple Random                0.698925  0.967742  \n",
      "Stratified                   0.677419  0.989247  \n",
      "Systematic                   0.763441  0.978495  \n"
     ]
    }
   ],
   "source": [
    "pivot_table = results_df.pivot(index=\"Sampling\", columns=\"Model\", values=\"Accuracy\")\n",
    "print(pivot_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
